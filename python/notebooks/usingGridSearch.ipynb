{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import os\n",
    "import rioxarray\n",
    "from typing import Optional, Tuple\n",
    "import subprocess\n",
    "import hvplot.xarray\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "#from scripts.funcs import fsm, square_melt_region, map_water_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scripts.funcs as fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64c1fbd11ee24eb792ce9fdee6182cb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2K"
     ]
    }
   ],
   "source": [
    "results = fun.gridSearch(fun.fsm_xarray, x_center_of_melt = [812500.0, 817500.0], melt_magnitude=[0.2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14aba75b4b1144e3b3526deb2b948757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BokehModel(combine_events=True, render_bundle={'docs_json': {'e4e68022-c1c5-43d0-ae65-54de2d94ddc4': {'version…"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fun.map_water_depth(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6a5e39fd5824962bcff503a4deade7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2K/Users/jkingslake/miniconda3/envs/full_py_env/lib/python3.11/site-packages/xarray/core/dataset.py:5525: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  result = result._unstack_full_reindex(\n",
      "/Users/jkingslake/miniconda3/envs/full_py_env/lib/python3.11/site-packages/xarray/core/dataset.py:5525: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  result = result._unstack_full_reindex(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = fun.gridSearch(fun.fsm_xarray, dem_filename = [\"/Users/jkingslake/Documents/science/meltwater_routing/big_data/boudouin_west_1_coarsen6_largerROI.tif\"],\n",
    "                         x_center_of_melt=np.arange(9.000e5,9.4e5,5000), \n",
    "                         y_center_of_melt=np.arange(1.866e6, 1.95e6, 5000), \n",
    "                         melt_magnitude=[0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_big = results.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jkingslake/miniconda3/envs/full_py_env/lib/python3.11/site-packages/xarray/core/rolling.py:1121: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  reduced[key] = da.variable.coarsen(\n",
      "/Users/jkingslake/miniconda3/envs/full_py_env/lib/python3.11/site-packages/xarray/core/rolling.py:1121: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  reduced[key] = da.variable.coarsen(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0faa3084f15e42b492097c2b32d1b734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BokehModel(combine_events=True, render_bundle={'docs_json': {'0f878637-e0ac-4f27-af7b-0af713293481': {'version…"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fun.map_water_depth(results, width=700, height=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "full_py_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
